{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-21T06:20:09.644384Z","iopub.execute_input":"2023-06-21T06:20:09.645296Z","iopub.status.idle":"2023-06-21T06:20:09.659638Z","shell.execute_reply.started":"2023-06-21T06:20:09.645250Z","shell.execute_reply":"2023-06-21T06:20:09.658396Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/news-clickbait-dataset/train1.csv\n/kaggle/input/news-clickbait-dataset/train2.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:36.037896Z","iopub.execute_input":"2023-06-21T06:20:36.038484Z","iopub.status.idle":"2023-06-21T06:20:36.044782Z","shell.execute_reply.started":"2023-06-21T06:20:36.038433Z","shell.execute_reply":"2023-06-21T06:20:36.043716Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train1_data = pd.read_csv(\"../input/news-clickbait-dataset/train1.csv\")\nHeadlines = train1_data[\"headline\"]\nClassification = train1_data[\"clickbait\"]","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:38.863089Z","iopub.execute_input":"2023-06-21T06:20:38.863456Z","iopub.status.idle":"2023-06-21T06:20:38.906986Z","shell.execute_reply.started":"2023-06-21T06:20:38.863426Z","shell.execute_reply":"2023-06-21T06:20:38.906002Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n  text = re.sub(r',', '', text)\n  text = re.sub(r'\\'', '',  text)\n  text = re.sub(r'\\\"', '', text)\n  text = re.sub(r'\\(', '', text)\n  text = re.sub(r'\\)', '', text)\n  text = re.sub(r'\\n', '', text)\n  text = re.sub(r'“', '', text)\n  text = re.sub(r'”', '', text)\n  text = re.sub(r'’', '', text)\n  text = re.sub(r'\\.', '', text)\n  text = re.sub(r';', '', text)\n  text = re.sub(r':', '', text)\n  text = re.sub(r'\\-', '', text)\n\n  return text\n","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:41.464246Z","iopub.execute_input":"2023-06-21T06:20:41.464600Z","iopub.status.idle":"2023-06-21T06:20:41.472980Z","shell.execute_reply.started":"2023-06-21T06:20:41.464571Z","shell.execute_reply":"2023-06-21T06:20:41.471804Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"clickbait_sentences = []\n\nfor i,headline in enumerate(Headlines):\n    if Classification[i] == 1:\n        clickbait_sentences.append(clean_text(headline))\n        \nclickbait_sentences = [text.lower() for text in clickbait_sentences]","metadata":{"execution":{"iopub.status.busy":"2023-06-21T09:42:00.570972Z","iopub.execute_input":"2023-06-21T09:42:00.571946Z","iopub.status.idle":"2023-06-21T09:42:01.024043Z","shell.execute_reply.started":"2023-06-21T09:42:00.571913Z","shell.execute_reply":"2023-06-21T09:42:01.023001Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Preprocess and tokenize the sentences\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(clickbait_sentences)\nindexed_sentences = tokenizer.texts_to_sequences(clickbait_sentences)\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2023-06-21T09:41:56.064397Z","iopub.execute_input":"2023-06-21T09:41:56.064813Z","iopub.status.idle":"2023-06-21T09:41:56.592112Z","shell.execute_reply.started":"2023-06-21T09:41:56.064782Z","shell.execute_reply":"2023-06-21T09:41:56.591187Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# Create n-gram sequences from the sentences\ninput_seq = []\nfor sentence in indexed_sentences:\n    for i in range(1, len(sentence)):\n        n_gram_seq = sentence[:i+1]\n        input_seq.append(n_gram_seq)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:51.910277Z","iopub.execute_input":"2023-06-21T06:20:51.910904Z","iopub.status.idle":"2023-06-21T06:20:52.353240Z","shell.execute_reply.started":"2023-06-21T06:20:51.910871Z","shell.execute_reply":"2023-06-21T06:20:52.352232Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Pad the sequences\nmax_seq_length = max(len(x) for x in input_seq)\ninput_seq = pad_sequences(input_seq, maxlen=max_seq_length, padding='pre')\n\n# Split the input sequences into input (xs) and label (labels)\nxs = input_seq[:, :-1]\nlabels = input_seq[:, -1]\n\n# One-hot encode the labels\nys = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:55.315745Z","iopub.execute_input":"2023-06-21T06:20:55.316121Z","iopub.status.idle":"2023-06-21T06:20:56.311259Z","shell.execute_reply.started":"2023-06-21T06:20:55.316093Z","shell.execute_reply":"2023-06-21T06:20:56.310170Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Define the model architecture\ninput_size = max_seq_length - 1\nembedding_size = 124\nlstm_units = 520\nbidirectional_lstm_units = 340\ndense_units = 1024\n\ninput_layer = Input(shape=(input_size,))\nembedding_layer = Embedding(vocab_size, embedding_size)(input_layer)\ndropout_layer = Dropout(0.2)(embedding_layer)\nlstm_layer = LSTM(lstm_units, return_sequences=True)(dropout_layer)\nbidirectional_lstm_layer = Bidirectional(LSTM(bidirectional_lstm_units, return_sequences=True))(lstm_layer)\npooling_layer = GlobalMaxPooling1D()(bidirectional_lstm_layer)\ndense_layer1 = Dense(dense_units, activation='relu')(pooling_layer)\noutput_layer = Dense(vocab_size, activation='softmax')(dense_layer1)\n\nmodel = Model(input_layer, output_layer)\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(xs, ys, epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T06:20:59.810290Z","iopub.execute_input":"2023-06-21T06:20:59.810689Z","iopub.status.idle":"2023-06-21T08:46:52.775319Z","shell.execute_reply.started":"2023-06-21T06:20:59.810629Z","shell.execute_reply":"2023-06-21T08:46:52.774180Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/100\n4471/4471 [==============================] - 119s 24ms/step - loss: 6.8691 - accuracy: 0.0675\nEpoch 2/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 6.1379 - accuracy: 0.1224\nEpoch 3/100\n4471/4471 [==============================] - 89s 20ms/step - loss: 5.6705 - accuracy: 0.1545\nEpoch 4/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 5.3077 - accuracy: 0.1769\nEpoch 5/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 5.0131 - accuracy: 0.1934\nEpoch 6/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 4.7680 - accuracy: 0.2091\nEpoch 7/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 4.5587 - accuracy: 0.2202\nEpoch 8/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 4.3767 - accuracy: 0.2315\nEpoch 9/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 4.2161 - accuracy: 0.2402\nEpoch 10/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 4.0655 - accuracy: 0.2507\nEpoch 11/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 3.9231 - accuracy: 0.2603\nEpoch 12/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.7879 - accuracy: 0.2719\nEpoch 13/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.6594 - accuracy: 0.2821\nEpoch 14/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 3.5393 - accuracy: 0.2927\nEpoch 15/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.4214 - accuracy: 0.3040\nEpoch 16/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 3.3127 - accuracy: 0.3170\nEpoch 17/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.2095 - accuracy: 0.3284\nEpoch 18/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.1102 - accuracy: 0.3423\nEpoch 19/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 3.0129 - accuracy: 0.3547\nEpoch 20/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 2.9264 - accuracy: 0.3673\nEpoch 21/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.8401 - accuracy: 0.3798\nEpoch 22/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.7619 - accuracy: 0.3924\nEpoch 23/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 2.6829 - accuracy: 0.4036\nEpoch 24/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.6093 - accuracy: 0.4172\nEpoch 25/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.5386 - accuracy: 0.4294\nEpoch 26/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.4756 - accuracy: 0.4397\nEpoch 27/100\n4471/4471 [==============================] - 89s 20ms/step - loss: 2.4112 - accuracy: 0.4518\nEpoch 28/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 2.3461 - accuracy: 0.4628\nEpoch 29/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.2806 - accuracy: 0.4753\nEpoch 30/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.2316 - accuracy: 0.4846\nEpoch 31/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.1792 - accuracy: 0.4942\nEpoch 32/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.1260 - accuracy: 0.5041\nEpoch 33/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.0691 - accuracy: 0.5146\nEpoch 34/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 2.0273 - accuracy: 0.5227\nEpoch 35/100\n4471/4471 [==============================] - 87s 20ms/step - loss: 1.9803 - accuracy: 0.5317\nEpoch 36/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.9346 - accuracy: 0.5418\nEpoch 37/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.8981 - accuracy: 0.5492\nEpoch 38/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.8562 - accuracy: 0.5569\nEpoch 39/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.8224 - accuracy: 0.5643\nEpoch 40/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.7862 - accuracy: 0.5729\nEpoch 41/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.7590 - accuracy: 0.5771\nEpoch 42/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.7278 - accuracy: 0.5829\nEpoch 43/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.6934 - accuracy: 0.5910\nEpoch 44/100\n 148/4471 [..............................] - ETA: 1:24 - loss: 1.5119 - accuracy: 0.6265","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"4471/4471 [==============================] - 86s 19ms/step - loss: 1.6667 - accuracy: 0.5965\nEpoch 45/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.6404 - accuracy: 0.6015\nEpoch 46/100\n3679/4471 [=======================>......] - ETA: 15s - loss: 1.6022 - accuracy: 0.6110","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"4471/4471 [==============================] - 86s 19ms/step - loss: 1.5903 - accuracy: 0.6141\nEpoch 48/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.5697 - accuracy: 0.6174\nEpoch 49/100\n2978/4471 [==================>...........] - ETA: 28s - loss: 1.5070 - accuracy: 0.6308","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"4471/4471 [==============================] - 86s 19ms/step - loss: 1.5262 - accuracy: 0.6271\nEpoch 51/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.5057 - accuracy: 0.6310\nEpoch 52/100\n2596/4471 [================>.............] - ETA: 35s - loss: 1.4361 - accuracy: 0.6468","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"4471/4471 [==============================] - 86s 19ms/step - loss: 1.4718 - accuracy: 0.6381\nEpoch 54/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.4568 - accuracy: 0.6433\nEpoch 55/100\n2541/4471 [================>.............] - ETA: 36s - loss: 1.4019 - accuracy: 0.6547","output_type":"stream"},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"name":"stdout","text":"4471/4471 [==============================] - 86s 19ms/step - loss: 1.4216 - accuracy: 0.6512\nEpoch 57/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.4153 - accuracy: 0.6506\nEpoch 58/100\n4471/4471 [==============================] - 88s 20ms/step - loss: 1.3963 - accuracy: 0.6555\nEpoch 59/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3879 - accuracy: 0.6589\nEpoch 60/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.3771 - accuracy: 0.6618\nEpoch 61/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3665 - accuracy: 0.6626\nEpoch 62/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3503 - accuracy: 0.6676\nEpoch 63/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3426 - accuracy: 0.6682\nEpoch 64/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.3297 - accuracy: 0.6728\nEpoch 65/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3259 - accuracy: 0.6723\nEpoch 66/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.3220 - accuracy: 0.6731\nEpoch 67/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.3090 - accuracy: 0.6778\nEpoch 68/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2972 - accuracy: 0.6791\nEpoch 69/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2888 - accuracy: 0.6808\nEpoch 70/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2871 - accuracy: 0.6830\nEpoch 71/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2805 - accuracy: 0.6843\nEpoch 72/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2746 - accuracy: 0.6854\nEpoch 73/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2654 - accuracy: 0.6867\nEpoch 74/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2560 - accuracy: 0.6908\nEpoch 75/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2516 - accuracy: 0.6908\nEpoch 76/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2501 - accuracy: 0.6900\nEpoch 77/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2436 - accuracy: 0.6925\nEpoch 78/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2363 - accuracy: 0.6946\nEpoch 79/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2332 - accuracy: 0.6953\nEpoch 80/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2317 - accuracy: 0.6957\nEpoch 81/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2214 - accuracy: 0.6991\nEpoch 82/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2128 - accuracy: 0.7003\nEpoch 83/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2155 - accuracy: 0.7000\nEpoch 84/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2099 - accuracy: 0.7008\nEpoch 85/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2103 - accuracy: 0.7009\nEpoch 86/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.2025 - accuracy: 0.7034\nEpoch 87/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.2078 - accuracy: 0.7023\nEpoch 88/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1944 - accuracy: 0.7046\nEpoch 89/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1937 - accuracy: 0.7068\nEpoch 90/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.1992 - accuracy: 0.7033\nEpoch 91/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1910 - accuracy: 0.7062\nEpoch 92/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1840 - accuracy: 0.7086\nEpoch 93/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1806 - accuracy: 0.7089\nEpoch 94/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1851 - accuracy: 0.7092\nEpoch 95/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1820 - accuracy: 0.7097\nEpoch 96/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1781 - accuracy: 0.7102\nEpoch 97/100\n4471/4471 [==============================] - 86s 19ms/step - loss: 1.1720 - accuracy: 0.7118\nEpoch 98/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1746 - accuracy: 0.7120\nEpoch 99/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1680 - accuracy: 0.7136\nEpoch 100/100\n4471/4471 [==============================] - 87s 19ms/step - loss: 1.1731 - accuracy: 0.7126\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_text(seed_text, num_words):\n    for _ in range(num_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=input_size, padding='pre')\n        predicted = model.predict(token_list)\n        predicted_word_index = np.argmax(predicted)\n        predicted_word = tokenizer.index_word[predicted_word_index]\n        seed_text += \" \" + predicted_word\n    return seed_text","metadata":{"execution":{"iopub.status.busy":"2023-06-21T09:42:11.725120Z","iopub.execute_input":"2023-06-21T09:42:11.725542Z","iopub.status.idle":"2023-06-21T09:42:11.732581Z","shell.execute_reply.started":"2023-06-21T09:42:11.725509Z","shell.execute_reply":"2023-06-21T09:42:11.731219Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Save the model\nmodel.save(\"clickbait_generator.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-06-21T08:47:08.165195Z","iopub.execute_input":"2023-06-21T08:47:08.165601Z","iopub.status.idle":"2023-06-21T08:47:08.836112Z","shell.execute_reply.started":"2023-06-21T08:47:08.165572Z","shell.execute_reply":"2023-06-21T08:47:08.834782Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Example usage\nseed_text = \"programming finance\"\nnum_words = 10\ngenerated_text = generate_text(seed_text, num_words)\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2023-06-21T09:45:45.693406Z","iopub.execute_input":"2023-06-21T09:45:45.693788Z","iopub.status.idle":"2023-06-21T09:45:46.317880Z","shell.execute_reply.started":"2023-06-21T09:45:45.693757Z","shell.execute_reply":"2023-06-21T09:45:46.316874Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 21ms/step\n1/1 [==============================] - 0s 22ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\nprogramming finance yourself the disabled dwarf musical of last gomez and more\n","output_type":"stream"}]}]}